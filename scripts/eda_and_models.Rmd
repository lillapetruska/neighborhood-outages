---
title: "EDA and Predictive Models"
author: "Matt Alvarez-Nissen"
date: "10/21/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Script Description
This analyzes merged ACS and PG&E data. Conducts EDA and generates predictive 
models.

# Inputs:
Merged ACS/PG&E data

# Outputs:
EDA visualizations
Predictive model outcomes

# Update log: 

# Setup 
```{r, warning=FALSE, message=FALSE}
# Packages: 
library(tidyverse)
library(Hmisc)
library(data.table)
library(foreach)
library(skimr)
library(knitr)
library(kableExtra)
library(GGally)
library(caret)
library(pROC)
library(corrr)

# Directories: 
homedir <- "E:/neighborhood-outages/"
workdir <- "cleaned_data/"
savedir <- "visualizations/"

# Import data: 
acs_outages <- 
  read_csv(paste0(homedir, workdir, "acs_outages_train.csv"))

# Parameters:
## List of outcome variables
outcome_vars <- c("median_outage_duration_hr", "above_median_cust_affected")

## List of covariates
continuous_vars <- 
  names(acs_outages %>% select(-c(all_of(outcome_vars), GEOID)))
```

  
# Main Script

# EDA
## Summary statistics
```{r}
summary(acs_outages)
```

```{r}
skim(acs_outages)
```

## Missing values
```{r}
# NA values?
# Filter all the columns to exclude NA
no_na_df <-
  acs_outages %>% 
  filter(across(everything(), ~ !is.na(.)))

acs_outages %>% 
  filter(!(GEOID %in% no_na_df$GEOID)) %>% 
  arrange(desc(prop_white))
```

Not that many NAs, not sure if worth dropping. Some rows with NAs have otherwise
valuable data.

```{r}
# NULL values?
# Filter all the columns to exclude NA
no_null_df <-
  acs_outages %>% 
  filter(across(everything(), ~ !is.null(.)))

acs_outages %>% 
  filter(!(GEOID %in% no_null_df$GEOID)) %>% 
  arrange(desc(prop_white))
```

No NULL values.

## Correlations
```{r}
### Generate correlation matrices with p-values ###

# remove continuous/outcome vars if sd < 0
corr_matrix <- 
  acs_outages %>%
  select(all_of(continuous_vars), all_of(outcome_vars)) %>% 
  select(where(~sd(., na.rm = TRUE) > 0))

# create correlation matrix
corr_matrix <- rcorr(as.matrix(corr_matrix)) 
corr_matrix <- 
  # merge p-values
  bind_cols(
    as.data.frame(corr_matrix$r),
    as.data.frame(corr_matrix$P) %>% rename_all(~paste0(.x, "_p-value")) 
  ) %>%
  # filter to relevant predictor and outcome variables
  select(all_of(outcome_vars), all_of(paste0(outcome_vars, "_p-value"))) %>%
  rownames_to_column(var = "predictor") %>%
  filter(
    predictor %in% c(continuous_vars, paste0(continuous_vars, "_p-value"))
  ) %>%
  column_to_rownames(var = "predictor") %>%
  select(sort(colnames(.))) %>%
  as.data.frame()
```

```{r}
### Filter to highest correlated & statistical significant ###
# For each outcome variable, select significant correlations (in abs value)

# create list of variables to use as a filter
corr_top <- foreach(out = outcome_vars) %do% {
  out_p <- paste0(out, "_p-value")
  corr_matrix %>%
    select(!!out, !!out_p) %>%
    filter(!!sym(out_p) < 0.05) %>%
    arrange(desc(abs(.))) %>%
    # slice to the top 10 results
    # head(10) %>%
    # extract the rownames for filtering
    rename_all(~str_remove(., "outcome_")) %>%
    rownames_to_column(var = "predictor") %>%
    mutate(predictor = str_remove(predictor, "continuous_"))
}
names(corr_top) <- str_remove(outcome_vars, "outcome_")

corr_top$median_outage_duration_hr %>% 
  kable(caption = "Median Outage Duration Correlations") %>% 
  kableExtra::kable_classic() %>% 
  #format for markdown
  kable_styling(latex_options="scale_down")
```

```{r}
corr_top$above_median_cust_affected %>% 
  kable(caption = "Above Median Customer Affected Correlations") %>% 
  kableExtra::kable_classic() %>% 
  #format for markdown
  kable_styling(latex_options="scale_down")
```

```{r, warning=FALSE, message=FALSE, fig.width=10, fig.height=8}
# create ggpairs scatterplot - looking at top 10 correlations
# visualize data to choose transformation

 
# make a function to plot generic data with points and a loess line
my_fn <- function(data, mapping, method="loess", ...){
  p <- ggplot(data = data, mapping = mapping) +
    geom_point(size = 0.01) +
    geom_smooth(method=method, formula = y ~ x, ...)
  return(p)
}

acs_outages %>%
  select(-GEOID) %>%
  # filter to significantly correlated variables
  select(
    all_of(outcome_vars),
    corr_top$median_outage_duration_hr$predictor %>% head(10), 
    corr_top$above_median_cust_affected$predictor %>% head(10)
  ) %>% 
  ggpairs(
    upper = list(continuous = wrap("cor", size = 2), size = 0.01),
    lower = list(continuous = my_fn, combo = wrap("facethist", binwidth = .1)),
    progress = FALSE
  ) +
  theme_grey(base_size = 5)
```

```{r}
# find variables most correlated to each other
# (select correlations w/ abs > .5)
covariate_corr <-
  acs_outages %>%
  select(all_of(continuous_vars), all_of(outcome_vars)) %>% 
  # drop prop owner
  select(-prop_owner) %>% 
  select(where(~sd(., na.rm = TRUE) > 0)) %>% 
  correlate() %>% 
  stretch() %>% 
  arrange(r) %>% 
  filter(abs(r) > .5) 

# reformat in formula form
interaction_vars <-
  covariate_corr %>% 
  mutate(lead_y = lead(y)) %>% 
  filter(x != lead_y) %>% 
  select(x, y) %>% 
  unite(col = "interact", sep = ":") %>%
  unlist() %>% 
  paste(collapse = " + ")
covariate_corr
```


## Median outage histogram
```{r}
acs_outages %>% 
  ggplot(aes(x = median_outage_duration_hr)) +
  geom_histogram(bins = 100)
```

## Above average customer affected distribution plot
```{r}
acs_outages %>% 
  ggplot(aes(x = as.factor(above_median_cust_affected))) +
  geom_bar(aes(y = (..count..)/sum(..count..))) + 
  labs(
    x = "Above Median Customers Affected",
    y = "Proportion of Data"
  )
```

## Bar plots
### Race
```{r, message=FALSE, warning=FALSE}
acs_outages %>% 
  pivot_longer(
    cols = prop_white:prop_latino,
    names_to = "race",
    values_to = "prop_race"
  ) %>% 
  mutate(
    race =str_to_title(str_replace_all(str_remove(race, "^prop_"), "_", " "))
  ) %>% 
  select(all_of(outcome_vars), race, prop_race) %>% 
  ggplot(aes(x = median_outage_duration_hr, y = prop_race, color = race)) +
  geom_point(alpha = .4) +
  geom_smooth()
```

```{r}
acs_outages %>% 
  pivot_longer(
    cols = prop_white:prop_latino,
    names_to = "race",
    values_to = "prop_race"
  ) %>% 
  mutate(
    race =str_to_title(str_replace_all(str_remove(race, "^prop_"), "_", " "))
  ) %>% 
  select(all_of(outcome_vars), race, prop_race) %>% 
  group_by(above_median_cust_affected, race) %>% 
  summarise(prop_race_mean = mean(prop_race, na.rm = TRUE)) %>% 
  ggplot(
    aes(
      x = as_factor(above_median_cust_affected), 
      y = prop_race_mean, 
      fill = race
    )
  ) +
  geom_col()
```

### Population density
```{r}
acs_outages %>% 
  ggplot(aes(x = median_outage_duration_hr, y = pop_density_sq_km)) +
  geom_point(alpha = .4) +
  geom_smooth()
```

```{r}
acs_outages %>% 
  ggplot(
    aes(
      x = as_factor(above_median_cust_affected), 
      y = pop_density_sq_km
    )
  ) +
  geom_col()
```

### AMI Groups
```{r, message=FALSE, warning=FALSE}
acs_outages %>% 
  pivot_longer(
    cols = prop_eli:prop_vli,
    names_to = "ami_group",
    values_to = "prop_ami_group"
  ) %>%  
  mutate(
    ami_group = 
      str_to_upper(str_replace_all(str_remove(ami_group, "^prop_"), "_", " "))
  ) %>% 
  select(all_of(outcome_vars), ami_group, prop_ami_group) %>% 
  ggplot(
    aes(x = median_outage_duration_hr, y = prop_ami_group, color = ami_group)
  ) +
  geom_point(alpha = .4) +
  geom_smooth()
```

```{r, warning=FALSE, message=FALSE}
acs_outages %>% 
 pivot_longer(
    cols = prop_eli:prop_vli,
    names_to = "ami_group",
    values_to = "prop_ami_group"
  ) %>% 
  mutate(
    race =
      str_to_upper(str_replace_all(str_remove(ami_group, "^prop_"), "_", " "))
  ) %>% 
  select(all_of(outcome_vars), ami_group, prop_ami_group) %>% 
  group_by(above_median_cust_affected, ami_group) %>% 
  summarise(prop_ami_mean = mean(prop_ami_group, na.rm = TRUE)) %>% 
  ggplot(
    aes(
      x = as_factor(above_median_cust_affected), 
      y = prop_ami_mean, 
      fill = ami_group
    )
  ) +
  geom_col()
```

### Education
```{r, message=FALSE, warning=FALSE}
acs_outages %>% 
  pivot_longer(
    cols = prop_college:prop_less_than_hs,
    names_to = "education",
    values_to = "prop_education"
  ) %>%   
  mutate(
    education = 
      str_to_title(str_replace_all(str_remove(education, "^prop_"), "_", " "))
  ) %>% 
  select(all_of(outcome_vars), education, prop_education) %>% 
  ggplot(
    aes(x = median_outage_duration_hr, y = prop_education, color = education)
  ) +
  geom_point(alpha = .4) +
  geom_smooth()
```

```{r, warning=FALSE, message=FALSE}
acs_outages %>% 
  pivot_longer(
    cols = prop_college:prop_less_than_hs,
    names_to = "education",
    values_to = "prop_education"
  ) %>% 
  mutate(
    education =
      str_to_upper(str_replace_all(str_remove(education, "^prop_"), "_", " "))
  ) %>% 
  select(all_of(outcome_vars), education, prop_education) %>% 
  group_by(above_median_cust_affected, education) %>% 
  summarise(prop_education_mean = mean(prop_education, na.rm = TRUE)) %>% 
  ggplot(
    aes(
      x = as_factor(above_median_cust_affected), 
      y = prop_education_mean, 
      fill = education
    )
  ) +
  geom_col()
```

### Tenure
```{r, message=FALSE, warning=FALSE}
acs_outages %>% 
  pivot_longer(
    cols = prop_owner:prop_renter,
    names_to = "tenure",
    values_to = "prop_tenure"
  ) %>%    
  mutate(
    tenure = 
      str_to_title(str_replace_all(str_remove(tenure, "^prop_"), "_", " "))
  ) %>% 
  select(all_of(outcome_vars), tenure, prop_tenure) %>% 
  ggplot(
    aes(x = median_outage_duration_hr, y = prop_tenure, color = tenure)
  ) +
  geom_point(alpha = .4) +
  geom_smooth()
```

```{r, warning=FALSE, message=FALSE}
acs_outages %>% 
  pivot_longer(
    cols = prop_owner:prop_renter,
    names_to = "tenure",
    values_to = "prop_tenure"
  ) %>% 
  mutate(
    tenure =
      str_to_upper(str_replace_all(str_remove(tenure, "^prop_"), "_", " "))
  ) %>% 
  select(all_of(outcome_vars), tenure, prop_tenure) %>% 
  group_by(above_median_cust_affected, tenure) %>% 
  summarise(prop_tenure_mean = mean(prop_tenure, na.rm = TRUE)) %>% 
  ggplot(
    aes(
      x = as_factor(above_median_cust_affected), 
      y = prop_tenure_mean, 
      fill = tenure
    )
  ) +
  geom_col()
```

### Vacancy rates
```{r, message=FALSE, warning=FALSE}
acs_outages %>% 
  pivot_longer(
    cols = rental_vacancy_rate:owner_vacancy_rate,
    names_to = "vacancy_type",
    values_to = "vacancy_rate"
  ) %>%  
  mutate(
    vacancy_type = 
      str_to_title(str_replace_all(str_remove(vacancy_type, "^prop_"), "_", " "))
  ) %>% 
  select(all_of(outcome_vars), vacancy_type, vacancy_rate) %>% 
  ggplot(
    aes(x = median_outage_duration_hr, y = vacancy_rate, color = vacancy_type)
  ) +
  geom_point(alpha = .4) +
  geom_smooth()
```

```{r, warning=FALSE, message=FALSE}
acs_outages %>% 
  pivot_longer(
    cols = rental_vacancy_rate:owner_vacancy_rate,
    names_to = "vacancy_type",
    values_to = "vacancy_rate"
  ) %>% 
  mutate(
    vacancy_type =
      str_to_upper(str_replace_all(str_remove(vacancy_type, "^prop_"), "_", " "))
  ) %>% 
  select(all_of(outcome_vars), vacancy_type, vacancy_rate) %>% 
  group_by(above_median_cust_affected, vacancy_type) %>% 
  summarise(prop_vacancy_mean = mean(vacancy_rate, na.rm = TRUE)) %>% 
  ggplot(
    aes(
      x = as_factor(above_median_cust_affected), 
      y = prop_vacancy_mean, 
      fill = vacancy_type
    )
  ) +
  geom_col(position = "dodge")
```

# Predictive models
## Regression
### Baseline model
```{r}
# baseline_lm <- lm([INSERT OUTCOME HERE] ~ ., data = outages_full)
```

## Classification
### Baseline model (logistic regression)
```{r}
# Set up data for classification (and drop NAs)
acs_outages_class <- 
  acs_outages %>% 
  select(-c(GEOID, median_outage_duration_hr)) %>% 
  drop_na() 
```

```{r}
# Look at results of the model
logit_mod <-
  glm(
    above_median_cust_affected ~ .,
    data = acs_outages_class, 
    family = binomial
  )
summary(logit_mod)
```

AIC is 1996.2.

```{r}
# Create confusion matrix
pred <- 
  if_else(logit_mod$fitted.values > 0.5, "1", "0")

confusion_matrix <-
  table(acs_outages_class$above_median_cust_affected, pred)
rownames(confusion_matrix) <- c("Obs. 0", "Obs. 1")
colnames(confusion_matrix) <- c("Pred. 0", "Pred. 1")
confusion_matrix
```

```{r}
# calculate confusion matrix scores
tn <- confusion_matrix[1,1]
fn <- confusion_matrix[2,1]
fp <- confusion_matrix[1,2]
tp <- confusion_matrix[2,2]

base_01_loss <- (fp + fn) / nrow(acs_outages_class)
base_sensitivity <- tp / (fn + tp)
base_specificity <- tn / (tn + fp)
base_precision <- tp / (tp + fp)
base_typeI_error <- fp / (tn + fp)
base_typeII_error <- fn / (fn + tp)
base_false_discovery <- fp / (tp + fp)
```

```{r, warning=FALSE, message=FALSE}
# Plot ROC Curve
roc(
  response = acs_outages_class$above_median_cust_affected,
  predictor = logit_mod$fitted.values, 
  data = acs_outages_class, 
  plot = TRUE,
  main = "Baseline ROC",
  col = "blue"
)
```

```{r, warning=FALSE, message=FALSE}
# determine AUC
auc(
  response = acs_outages_class$above_median_cust_affected,
  predictor = logit_mod$fitted.values,  
  data = acs_outages_class
)
```

Major goal is optimize mean 0-1 loss and increase sensitivity. Logistic model is
a good baseline, but I want to see if I can improve those metrics. Will use PCA
to reduce covariates and eliminate some of the collinearity noticed in EDA. 
Then I'll take the factor loadings to conduct KNN classification. Will do a
10-fold cross-validation to ensure robustness of approach.

### Final model (PCA-based K-nearest neighbors algorithm)
```{r}
# conduct PCA (to reduce data, especially collinearity)

# Find variance of each covariate
train_col_var <- 
  acs_outages_class %>% 
  select(-above_median_cust_affected) %>% 
  mutate(across(everything(), stats::var)) %>% 
  distinct() %>% 
  pivot_longer(cols = everything(), names_to = "vars", values_to = "variance") %>% 
  # filter out 0 variance covariates
  filter(variance != 0)

# remove zero variance covariates
class_filter <-
  acs_outages_class %>% 
  # remove outcome var as well
  select(all_of(train_col_var$vars))

# Run PCA
pca <- prcomp(class_filter, scale = T, center = T)
summary(pca)
```

```{r}
# compute standard deviation of each principal component
std_dev <- pca$sdev
# compute variance
pr_var <- std_dev^2
# proportion of variance explained
prop_var <- pr_var/sum(pr_var)

# generate scree plot
plot(
  prop_var, 
  xlab = "Principal Component",
  ylab = "Proportion of Variance Explained",
  type = "b"
)
```
Around 13 components explains about 90% of variance.

```{r}
# PCA results
pca_table <- 
  data.frame(
    above_median_cust_affected = acs_outages_class[,1] %>% pull(), pca$x
  ) %>% 
  #filter to the first 16 components
  select(above_median_cust_affected:PC13) %>% 
  bind_cols()
```

```{r}
# Do 10-fold CV KNN
set.seed(243)
# Set train control
knn_control <- 
  trainControl(
    method = "cv", 
    number = 10
  )

# Evaluate accuracy of KNN classifiers
knn_fit <-
  train(
    as.factor(above_median_cust_affected) ~ .,
    method = "knn",
    # Limit to k = sqrt(n)
    tuneGrid = expand.grid(k = 1:sqrt(nrow(pca_table))),
    trControl = knn_control,
    metric = "Accuracy",
    data = pca_table
  )
```

```{r}
# create confusion matrix
confusion_matrix_knn <- confusionMatrix(knn_fit, positive = 1)
confusion_matrix_knn <- confusion_matrix_knn$table %>% t()
confusion_matrix_knn
```


```{r}
# calculate confusion matrix scores
tn <- confusion_matrix_knn[1,1]
fn <- confusion_matrix_knn[2,1]
fp <- confusion_matrix_knn[1,2]
tp <- confusion_matrix_knn[2,2]

final_01_loss <- (fp + fn) / nrow(acs_outages_class)
final_sensitivity <- tp / (fn + tp)
final_specificity <- tn / (tn + fp)
final_precision <- tp / (tp + fp)
final_typeI_error <- fp / (tn + fp)
final_typeII_error <- fn / (fn + tp)
final_false_discovery <- fp / (tp + fp)
```

```{r}
# confusion matrix comparison
confusion_matrix_comparison <-
  tibble(
    metric =
      c("Mean 0-1 Loss", "Precision", "Sensitivity", "Specificity",
        "Type I Error Rate", "Type II Error Rate", "False Discovery Rate"),
    base = 
      c(base_01_loss, base_precision, base_sensitivity, base_specificity,
        base_typeI_error, base_typeII_error, base_false_discovery),
    final = 
      c(final_01_loss, final_precision, final_sensitivity, final_specificity,
        final_typeI_error, final_typeII_error, final_false_discovery)
  ) %>% 
  kable(caption = "Above Median Customer Affected Confusion Matrix Metrics") %>% 
  kableExtra::kable_classic() %>% 
  #format for markdown
  kable_styling(latex_options="scale_down")
confusion_matrix_comparison
```

Some metrics take a hit (like precision and specificity), but Sensitivity
increased a good deal and the Mean 0-1 Loss improved as well - which were our 
choice outcomes. Want the model to detect as many true positives as possible.

```{r, warning=FALSE, message=FALSE}
# Plot ROC Curve
roc(
  response = pca_table$above_median_cust_affected,
  predictor = as.numeric(predict(knn_fit)), 
  data = pca_table, 
  plot = TRUE,
  main = "Final ROC",
  col = "blue"
)
```

```{r, warning=FALSE, message=FALSE}
# determine AUC
auc(
  response = pca_table$above_median_cust_affected,
  predictor = as.numeric(predict(knn_fit)),  
  data = pca_table
)
```

Clearly AUC and ROC take a hit, but this was not the goal of the model. Wanted 
to reduce mean 0-1 loss and increase sensitivity above all. This model is likely
biased, but the flag only appears 20% of the time I believe such bias is justified.
This is especially true because I wanted to optimize the sensitivity and accuracy 
of the model.